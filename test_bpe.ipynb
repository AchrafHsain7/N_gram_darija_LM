{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DarijaBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = '''Tokenization is the process of breaking down  \n",
    "a sequence of text into smaller units called tokens, \n",
    "which can be words, phrases, or even individual characters. \n",
    "Tokenization is often the first step in natural languages processing tasks  \n",
    "such as text classification, named entity recognition, and sentiment analysis. \n",
    "The resulting tokens are typically used as input to further processing steps, \n",
    "such as vectorization, where the tokens are converted \n",
    "into numerical representations for machine learning models to use.'''\n",
    "data = corpus.split('.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = DarijaBPETokenizer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'<SOS> t o k e n i z a t i o n <EOS>': 2,\n",
       "             '<SOS> i s <EOS>': 3,\n",
       "             '<SOS> t h e <EOS>': 8,\n",
       "             '<SOS> p r o c e s s <EOS>': 1,\n",
       "             '<SOS> o f <EOS>': 4,\n",
       "             '<SOS> b r e a k i n g <EOS>': 1,\n",
       "             '<SOS> d o w n <EOS>': 1,\n",
       "             '<SOS> a <EOS>': 10,\n",
       "             '<SOS> s e q u e n c e <EOS>': 1,\n",
       "             '<SOS> t e x t <EOS>': 2,\n",
       "             '<SOS> i n t o <EOS>': 2,\n",
       "             '<SOS> s m a l l e r <EOS>': 1,\n",
       "             '<SOS> u n i t s <EOS>': 1,\n",
       "             '<SOS> c a l l e d <EOS>': 1,\n",
       "             '<SOS> t o k e n s , <EOS>': 1,\n",
       "             '<SOS> w h i c h <EOS>': 1,\n",
       "             '<SOS> c a n <EOS>': 1,\n",
       "             '<SOS> b e <EOS>': 1,\n",
       "             '<SOS> w o r d s , <EOS>': 1,\n",
       "             '<SOS> p h r a s e s , <EOS>': 1,\n",
       "             '<SOS> o r <EOS>': 2,\n",
       "             '<SOS> e v e n <EOS>': 1,\n",
       "             '<SOS> i n d i v i d u a l <EOS>': 1,\n",
       "             '<SOS> c h a r a c t e r s <EOS>': 1,\n",
       "             '<SOS> o f t e n <EOS>': 1,\n",
       "             '<SOS> f i r s t <EOS>': 1,\n",
       "             '<SOS> s t e p <EOS>': 1,\n",
       "             '<SOS> i n <EOS>': 2,\n",
       "             '<SOS> n a t u r a l <EOS>': 1,\n",
       "             '<SOS> l a n g u a g e s <EOS>': 1,\n",
       "             '<SOS> p r o c e s s i n g <EOS>': 2,\n",
       "             '<SOS> t a s k s <EOS>': 1,\n",
       "             '<SOS> s u c h <EOS>': 2,\n",
       "             '<SOS> a s <EOS>': 7,\n",
       "             '<SOS> c l a s s i f i c a t i o n , <EOS>': 1,\n",
       "             '<SOS> n a m e d <EOS>': 1,\n",
       "             '<SOS> e n t i t y <EOS>': 1,\n",
       "             '<SOS> r e c o g n i t i o n , <EOS>': 1,\n",
       "             '<SOS> a n d <EOS>': 1,\n",
       "             '<SOS> s e n t i m e n t <EOS>': 1,\n",
       "             '<SOS> a n a l y s i s <EOS>': 1,\n",
       "             '<SOS> r e s u l t i n g <EOS>': 1,\n",
       "             '<SOS> t o k e n s <EOS>': 4,\n",
       "             '<SOS> a r e <EOS>': 4,\n",
       "             '<SOS> t y p i c a l l y <EOS>': 1,\n",
       "             '<SOS> u s e d <EOS>': 1,\n",
       "             '<SOS> i n p u t <EOS>': 1,\n",
       "             '<SOS> t o <EOS>': 12,\n",
       "             '<SOS> f u r t h e r <EOS>': 1,\n",
       "             '<SOS> s t e p s , <EOS>': 1,\n",
       "             '<SOS> v e c t o r i z a t i o n , <EOS>': 1,\n",
       "             '<SOS> w h e r e <EOS>': 1,\n",
       "             '<SOS> c o n v e r t e d <EOS>': 1,\n",
       "             '<SOS> n u m e r i c a l <EOS>': 1,\n",
       "             '<SOS> r e p r e s e n t a t i o n s <EOS>': 1,\n",
       "             '<SOS> f o r <EOS>': 1,\n",
       "             '<SOS> m a c h i n e <EOS>': 1,\n",
       "             '<SOS> l e a r n i n g <EOS>': 1,\n",
       "             '<SOS> m o d e l s <EOS>': 1,\n",
       "             '<SOS> u s e <EOS>': 2})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(bpe.data)\n",
    "bpe.vocab\n",
    "# print(bpe.tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<SOS>', 't')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.pattern_frequencies()\n",
    "bpe.frequent_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe.update_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'<SOS>t o k e n i z a t i o n <EOS>': 2,\n",
       "             '<SOS> i s <EOS>': 3,\n",
       "             '<SOS>t h e <EOS>': 8,\n",
       "             '<SOS> p r o c e s s <EOS>': 1,\n",
       "             '<SOS> o f <EOS>': 4,\n",
       "             '<SOS> b r e a k i n g <EOS>': 1,\n",
       "             '<SOS> d o w n <EOS>': 1,\n",
       "             '<SOS> a <EOS>': 10,\n",
       "             '<SOS> s e q u e n c e <EOS>': 1,\n",
       "             '<SOS>t e x t <EOS>': 2,\n",
       "             '<SOS> i n t o <EOS>': 2,\n",
       "             '<SOS> s m a l l e r <EOS>': 1,\n",
       "             '<SOS> u n i t s <EOS>': 1,\n",
       "             '<SOS> c a l l e d <EOS>': 1,\n",
       "             '<SOS>t o k e n s , <EOS>': 1,\n",
       "             '<SOS> w h i c h <EOS>': 1,\n",
       "             '<SOS> c a n <EOS>': 1,\n",
       "             '<SOS> b e <EOS>': 1,\n",
       "             '<SOS> w o r d s , <EOS>': 1,\n",
       "             '<SOS> p h r a s e s , <EOS>': 1,\n",
       "             '<SOS> o r <EOS>': 2,\n",
       "             '<SOS> e v e n <EOS>': 1,\n",
       "             '<SOS> i n d i v i d u a l <EOS>': 1,\n",
       "             '<SOS> c h a r a c t e r s <EOS>': 1,\n",
       "             '<SOS> o f t e n <EOS>': 1,\n",
       "             '<SOS> f i r s t <EOS>': 1,\n",
       "             '<SOS> s t e p <EOS>': 1,\n",
       "             '<SOS> i n <EOS>': 2,\n",
       "             '<SOS> n a t u r a l <EOS>': 1,\n",
       "             '<SOS> l a n g u a g e s <EOS>': 1,\n",
       "             '<SOS> p r o c e s s i n g <EOS>': 2,\n",
       "             '<SOS>t a s k s <EOS>': 1,\n",
       "             '<SOS> s u c h <EOS>': 2,\n",
       "             '<SOS> a s <EOS>': 7,\n",
       "             '<SOS> c l a s s i f i c a t i o n , <EOS>': 1,\n",
       "             '<SOS> n a m e d <EOS>': 1,\n",
       "             '<SOS> e n t i t y <EOS>': 1,\n",
       "             '<SOS> r e c o g n i t i o n , <EOS>': 1,\n",
       "             '<SOS> a n d <EOS>': 1,\n",
       "             '<SOS> s e n t i m e n t <EOS>': 1,\n",
       "             '<SOS> a n a l y s i s <EOS>': 1,\n",
       "             '<SOS> r e s u l t i n g <EOS>': 1,\n",
       "             '<SOS>t o k e n s <EOS>': 4,\n",
       "             '<SOS> a r e <EOS>': 4,\n",
       "             '<SOS>t y p i c a l l y <EOS>': 1,\n",
       "             '<SOS> u s e d <EOS>': 1,\n",
       "             '<SOS> i n p u t <EOS>': 1,\n",
       "             '<SOS>t o <EOS>': 12,\n",
       "             '<SOS> f u r t h e r <EOS>': 1,\n",
       "             '<SOS> s t e p s , <EOS>': 1,\n",
       "             '<SOS> v e c t o r i z a t i o n , <EOS>': 1,\n",
       "             '<SOS> w h e r e <EOS>': 1,\n",
       "             '<SOS> c o n v e r t e d <EOS>': 1,\n",
       "             '<SOS> n u m e r i c a l <EOS>': 1,\n",
       "             '<SOS> r e p r e s e n t a t i o n s <EOS>': 1,\n",
       "             '<SOS> f o r <EOS>': 1,\n",
       "             '<SOS> m a c h i n e <EOS>': 1,\n",
       "             '<SOS> l e a r n i n g <EOS>': 1,\n",
       "             '<SOS> m o d e l s <EOS>': 1,\n",
       "             '<SOS> u s e <EOS>': 2})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<SOS>', 'a')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.pattern_frequencies()\n",
    "bpe.frequent_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'<SOS>t o k e n i z a t i o n <EOS>': 2,\n",
       "             '<SOS> i s <EOS>': 3,\n",
       "             '<SOS>t h e <EOS>': 8,\n",
       "             '<SOS> p r o c e s s <EOS>': 1,\n",
       "             '<SOS> o f <EOS>': 4,\n",
       "             '<SOS> b r e a k i n g <EOS>': 1,\n",
       "             '<SOS> d o w n <EOS>': 1,\n",
       "             '<SOS>a <EOS>': 10,\n",
       "             '<SOS> s e q u e n c e <EOS>': 1,\n",
       "             '<SOS>t e x t <EOS>': 2,\n",
       "             '<SOS> i n t o <EOS>': 2,\n",
       "             '<SOS> s m a l l e r <EOS>': 1,\n",
       "             '<SOS> u n i t s <EOS>': 1,\n",
       "             '<SOS> c a l l e d <EOS>': 1,\n",
       "             '<SOS>t o k e n s , <EOS>': 1,\n",
       "             '<SOS> w h i c h <EOS>': 1,\n",
       "             '<SOS> c a n <EOS>': 1,\n",
       "             '<SOS> b e <EOS>': 1,\n",
       "             '<SOS> w o r d s , <EOS>': 1,\n",
       "             '<SOS> p h r a s e s , <EOS>': 1,\n",
       "             '<SOS> o r <EOS>': 2,\n",
       "             '<SOS> e v e n <EOS>': 1,\n",
       "             '<SOS> i n d i v i d u a l <EOS>': 1,\n",
       "             '<SOS> c h a r a c t e r s <EOS>': 1,\n",
       "             '<SOS> o f t e n <EOS>': 1,\n",
       "             '<SOS> f i r s t <EOS>': 1,\n",
       "             '<SOS> s t e p <EOS>': 1,\n",
       "             '<SOS> i n <EOS>': 2,\n",
       "             '<SOS> n a t u r a l <EOS>': 1,\n",
       "             '<SOS> l a n g u a g e s <EOS>': 1,\n",
       "             '<SOS> p r o c e s s i n g <EOS>': 2,\n",
       "             '<SOS>t a s k s <EOS>': 1,\n",
       "             '<SOS> s u c h <EOS>': 2,\n",
       "             '<SOS>a s <EOS>': 7,\n",
       "             '<SOS> c l a s s i f i c a t i o n , <EOS>': 1,\n",
       "             '<SOS> n a m e d <EOS>': 1,\n",
       "             '<SOS> e n t i t y <EOS>': 1,\n",
       "             '<SOS> r e c o g n i t i o n , <EOS>': 1,\n",
       "             '<SOS>a n d <EOS>': 1,\n",
       "             '<SOS> s e n t i m e n t <EOS>': 1,\n",
       "             '<SOS>a n a l y s i s <EOS>': 1,\n",
       "             '<SOS> r e s u l t i n g <EOS>': 1,\n",
       "             '<SOS>t o k e n s <EOS>': 4,\n",
       "             '<SOS>a r e <EOS>': 4,\n",
       "             '<SOS>t y p i c a l l y <EOS>': 1,\n",
       "             '<SOS> u s e d <EOS>': 1,\n",
       "             '<SOS> i n p u t <EOS>': 1,\n",
       "             '<SOS>t o <EOS>': 12,\n",
       "             '<SOS> f u r t h e r <EOS>': 1,\n",
       "             '<SOS> s t e p s , <EOS>': 1,\n",
       "             '<SOS> v e c t o r i z a t i o n , <EOS>': 1,\n",
       "             '<SOS> w h e r e <EOS>': 1,\n",
       "             '<SOS> c o n v e r t e d <EOS>': 1,\n",
       "             '<SOS> n u m e r i c a l <EOS>': 1,\n",
       "             '<SOS> r e p r e s e n t a t i o n s <EOS>': 1,\n",
       "             '<SOS> f o r <EOS>': 1,\n",
       "             '<SOS> m a c h i n e <EOS>': 1,\n",
       "             '<SOS> l e a r n i n g <EOS>': 1,\n",
       "             '<SOS> m o d e l s <EOS>': 1,\n",
       "             '<SOS> u s e <EOS>': 2})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.update_vocab()\n",
    "bpe.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'<SOS>tokenization<EOS>': 2,\n",
       "             '<SOS>is<EOS>': 3,\n",
       "             '<SOS>the<EOS>': 8,\n",
       "             '<SOS>process<EOS>': 1,\n",
       "             '<SOS>of<EOS>': 4,\n",
       "             '<SOS>breaking<EOS>': 1,\n",
       "             '<SOS>down<EOS>': 1,\n",
       "             '<SOS>a<EOS>': 10,\n",
       "             '<SOS>sequence<EOS>': 1,\n",
       "             '<SOS>text<EOS>': 2,\n",
       "             '<SOS>into<EOS>': 2,\n",
       "             '<SOS>smaller<EOS>': 1,\n",
       "             '<SOS>units<EOS>': 1,\n",
       "             '<SOS>called<EOS>': 1,\n",
       "             '<SOS>tokens,<EOS>': 1,\n",
       "             '<SOS>which<EOS>': 1,\n",
       "             '<SOS>can<EOS>': 1,\n",
       "             '<SOS>be<EOS>': 1,\n",
       "             '<SOS>words,<EOS>': 1,\n",
       "             '<SOS>phrases,<EOS>': 1,\n",
       "             '<SOS>or<EOS>': 2,\n",
       "             '<SOS>even<EOS>': 1,\n",
       "             '<SOS>individual<EOS>': 1,\n",
       "             '<SOS>characters<EOS>': 1,\n",
       "             '<SOS>often<EOS>': 1,\n",
       "             '<SOS>first<EOS>': 1,\n",
       "             '<SOS>step<EOS>': 1,\n",
       "             '<SOS>in<EOS>': 2,\n",
       "             '<SOS>natural<EOS>': 1,\n",
       "             '<SOS>languages<EOS>': 1,\n",
       "             '<SOS>processing<EOS>': 2,\n",
       "             '<SOS>tasks<EOS>': 1,\n",
       "             '<SOS>such<EOS>': 2,\n",
       "             '<SOS>as<EOS>': 7,\n",
       "             '<SOS>classification,<EOS>': 1,\n",
       "             '<SOS>named<EOS>': 1,\n",
       "             '<SOS>entity<EOS>': 1,\n",
       "             '<SOS>recognition,<EOS>': 1,\n",
       "             '<SOS>and<EOS>': 1,\n",
       "             '<SOS>sentiment<EOS>': 1,\n",
       "             '<SOS>analysis<EOS>': 1,\n",
       "             '<SOS>resulting<EOS>': 1,\n",
       "             '<SOS>tokens<EOS>': 4,\n",
       "             '<SOS>are<EOS>': 4,\n",
       "             '<SOS>typically<EOS>': 1,\n",
       "             '<SOS>used<EOS>': 1,\n",
       "             '<SOS>input<EOS>': 1,\n",
       "             '<SOS>to<EOS>': 12,\n",
       "             '<SOS>further<EOS>': 1,\n",
       "             '<SOS>steps,<EOS>': 1,\n",
       "             '<SOS>vectorization,<EOS>': 1,\n",
       "             '<SOS>where<EOS>': 1,\n",
       "             '<SOS>converted<EOS>': 1,\n",
       "             '<SOS>n u m er ic al<EOS>': 1,\n",
       "             '<SOS>re p res en t ation s<EOS>': 1,\n",
       "             '<SOS>f o r<EOS>': 1,\n",
       "             '<SOS>m ac h in e<EOS>': 1,\n",
       "             '<SOS>l e ar n ing<EOS>': 1,\n",
       "             '<SOS>m o d e l s<EOS>': 1,\n",
       "             '<SOS>use<EOS>': 2})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.bp_encode(228)\n",
    "bpe.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How It Actually Work LOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "def get_stats(vocab): \n",
    "    \"\"\" \n",
    "    Given a vocabulary (dictionary mapping words to frequency counts), returns a  \n",
    "    dictionary of tuples representing the frequency count of pairs of characters  \n",
    "    in the vocabulary. \n",
    "    \"\"\"\n",
    "    pairs = defaultdict(int) \n",
    "    for word, freq in vocab.items(): \n",
    "        symbols = word.split() \n",
    "        for i in range(len(symbols)-1): \n",
    "            pairs[symbols[i],symbols[i+1]] += freq \n",
    "    return pairs \n",
    "  \n",
    "def merge_vocab(pair, v_in): \n",
    "    \"\"\" \n",
    "    Given a pair of characters and a vocabulary, returns a new vocabulary with the  \n",
    "    pair of characters merged together wherever they appear. \n",
    "    \"\"\"\n",
    "    v_out = {} \n",
    "    bigram = re.escape(' '.join(pair)) \n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)') \n",
    "    for word in v_in: \n",
    "        w_out = p.sub(''.join(pair), word) \n",
    "        v_out[w_out] = v_in[word] \n",
    "    return v_out \n",
    "  \n",
    "def get_vocab(data): \n",
    "    \"\"\" \n",
    "    Given a list of strings, returns a dictionary of words mapping to their frequency  \n",
    "    count in the data. \n",
    "    \"\"\"\n",
    "    vocab = defaultdict(int) \n",
    "    for line in data: \n",
    "        for word in line.split(): \n",
    "            vocab[' '.join(list(word)) + ' </w>'] += 1\n",
    "    return vocab \n",
    "  \n",
    "def byte_pair_encoding(data, n): \n",
    "    \"\"\" \n",
    "    Given a list of strings and an integer n, returns a list of n merged pairs \n",
    "    of characters found in the vocabulary of the input data. \n",
    "    \"\"\"\n",
    "    vocab = get_vocab(data) \n",
    "    for i in range(n): \n",
    "        pairs = get_stats(vocab) \n",
    "        best = max(pairs, key=pairs.get) \n",
    "        vocab = merge_vocab(best, vocab) \n",
    "    return vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 230\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vocab \u001b[38;5;241m=\u001b[39m \u001b[43mget_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m vocab\n",
      "Cell \u001b[1;32mIn[15], line 32\u001b[0m, in \u001b[0;36mget_vocab\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vocab\u001b[39m(data): \n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    Given a list of strings, returns a dictionary of words mapping to their frequency  \u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    count in the data. \u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     vocab \u001b[38;5;241m=\u001b[39m \u001b[43mdefaultdict\u001b[49m(\u001b[38;5;28mint\u001b[39m) \n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m data: \n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m line\u001b[38;5;241m.\u001b[39msplit(): \n",
      "\u001b[1;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "vocab = get_vocab(data)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('T', 'o'): 2,\n",
       "             ('o', 'k'): 5,\n",
       "             ('k', 'e'): 5,\n",
       "             ('e', 'n'): 12,\n",
       "             ('n', 'i'): 5,\n",
       "             ('i', 'z'): 3,\n",
       "             ('z', 'a'): 3,\n",
       "             ('a', 't'): 6,\n",
       "             ('t', 'i'): 9,\n",
       "             ('i', 'o'): 6,\n",
       "             ('o', 'n'): 7,\n",
       "             ('n', '</w>'): 7,\n",
       "             ('i', 's'): 3,\n",
       "             ('s', '</w>'): 15,\n",
       "             ('t', 'h'): 4,\n",
       "             ('h', 'e'): 6,\n",
       "             ('e', '</w>'): 11,\n",
       "             ('p', 'r'): 4,\n",
       "             ('r', 'o'): 3,\n",
       "             ('o', 'c'): 3,\n",
       "             ('c', 'e'): 4,\n",
       "             ('e', 's'): 7,\n",
       "             ('s', 's'): 4,\n",
       "             ('o', 'f'): 3,\n",
       "             ('f', '</w>'): 2,\n",
       "             ('b', 'r'): 1,\n",
       "             ('r', 'e'): 8,\n",
       "             ('e', 'a'): 2,\n",
       "             ('a', 'k'): 1,\n",
       "             ('k', 'i'): 1,\n",
       "             ('i', 'n'): 11,\n",
       "             ('n', 'g'): 6,\n",
       "             ('g', '</w>'): 5,\n",
       "             ('d', 'o'): 1,\n",
       "             ('o', 'w'): 1,\n",
       "             ('w', 'n'): 1,\n",
       "             ('a', '</w>'): 1,\n",
       "             ('s', 'e'): 6,\n",
       "             ('e', 'q'): 1,\n",
       "             ('q', 'u'): 1,\n",
       "             ('u', 'e'): 1,\n",
       "             ('n', 'c'): 1,\n",
       "             ('t', 'e'): 7,\n",
       "             ('e', 'x'): 2,\n",
       "             ('x', 't'): 2,\n",
       "             ('t', '</w>'): 5,\n",
       "             ('n', 't'): 6,\n",
       "             ('t', 'o'): 8,\n",
       "             ('o', '</w>'): 4,\n",
       "             ('s', 'm'): 1,\n",
       "             ('m', 'a'): 2,\n",
       "             ('a', 'l'): 7,\n",
       "             ('l', 'l'): 3,\n",
       "             ('l', 'e'): 3,\n",
       "             ('e', 'r'): 6,\n",
       "             ('r', '</w>'): 4,\n",
       "             ('u', 'n'): 1,\n",
       "             ('i', 't'): 3,\n",
       "             ('t', 's'): 1,\n",
       "             ('c', 'a'): 5,\n",
       "             ('e', 'd'): 4,\n",
       "             ('d', '</w>'): 5,\n",
       "             ('n', 's'): 4,\n",
       "             ('s', ','): 4,\n",
       "             (',', '</w>'): 7,\n",
       "             ('w', 'h'): 2,\n",
       "             ('h', 'i'): 2,\n",
       "             ('i', 'c'): 4,\n",
       "             ('c', 'h'): 5,\n",
       "             ('h', '</w>'): 3,\n",
       "             ('a', 'n'): 4,\n",
       "             ('b', 'e'): 1,\n",
       "             ('w', 'o'): 1,\n",
       "             ('o', 'r'): 4,\n",
       "             ('r', 'd'): 1,\n",
       "             ('d', 's'): 1,\n",
       "             ('p', 'h'): 1,\n",
       "             ('h', 'r'): 1,\n",
       "             ('r', 'a'): 3,\n",
       "             ('a', 's'): 6,\n",
       "             ('e', 'v'): 1,\n",
       "             ('v', 'e'): 3,\n",
       "             ('n', 'd'): 2,\n",
       "             ('d', 'i'): 1,\n",
       "             ('i', 'v'): 1,\n",
       "             ('v', 'i'): 1,\n",
       "             ('i', 'd'): 1,\n",
       "             ('d', 'u'): 1,\n",
       "             ('u', 'a'): 2,\n",
       "             ('l', '</w>'): 3,\n",
       "             ('h', 'a'): 1,\n",
       "             ('a', 'r'): 4,\n",
       "             ('a', 'c'): 2,\n",
       "             ('c', 't'): 2,\n",
       "             ('r', 's'): 2,\n",
       "             ('f', 't'): 1,\n",
       "             ('f', 'i'): 2,\n",
       "             ('i', 'r'): 1,\n",
       "             ('s', 't'): 3,\n",
       "             ('e', 'p'): 3,\n",
       "             ('p', '</w>'): 1,\n",
       "             ('n', 'a'): 3,\n",
       "             ('t', 'u'): 1,\n",
       "             ('u', 'r'): 2,\n",
       "             ('l', 'a'): 2,\n",
       "             ('g', 'u'): 1,\n",
       "             ('a', 'g'): 1,\n",
       "             ('g', 'e'): 1,\n",
       "             ('s', 'i'): 4,\n",
       "             ('t', 'a'): 2,\n",
       "             ('s', 'k'): 1,\n",
       "             ('k', 's'): 1,\n",
       "             ('s', 'u'): 3,\n",
       "             ('u', 'c'): 2,\n",
       "             ('c', 'l'): 1,\n",
       "             ('i', 'f'): 1,\n",
       "             ('n', ','): 3,\n",
       "             ('a', 'm'): 1,\n",
       "             ('m', 'e'): 3,\n",
       "             ('t', 'y'): 2,\n",
       "             ('y', '</w>'): 2,\n",
       "             ('e', 'c'): 2,\n",
       "             ('c', 'o'): 2,\n",
       "             ('o', 'g'): 1,\n",
       "             ('g', 'n'): 1,\n",
       "             ('i', 'm'): 1,\n",
       "             ('l', 'y'): 2,\n",
       "             ('y', 's'): 1,\n",
       "             ('T', 'h'): 1,\n",
       "             ('u', 'l'): 1,\n",
       "             ('l', 't'): 1,\n",
       "             ('y', 'p'): 1,\n",
       "             ('p', 'i'): 1,\n",
       "             ('u', 's'): 2,\n",
       "             ('n', 'p'): 1,\n",
       "             ('p', 'u'): 1,\n",
       "             ('u', 't'): 1,\n",
       "             ('f', 'u'): 1,\n",
       "             ('r', 't'): 2,\n",
       "             ('p', 's'): 1,\n",
       "             ('r', 'i'): 2,\n",
       "             ('n', 'v'): 1,\n",
       "             ('n', 'u'): 1,\n",
       "             ('u', 'm'): 1,\n",
       "             ('f', 'o'): 1,\n",
       "             ('n', 'e'): 1,\n",
       "             ('r', 'n'): 1,\n",
       "             ('m', 'o'): 1,\n",
       "             ('o', 'd'): 1,\n",
       "             ('d', 'e'): 1,\n",
       "             ('e', 'l'): 1,\n",
       "             ('l', 's'): 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = get_stats(vocab)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s', '</w>')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = max(pairs, key=pairs.get)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s\\\\ </w>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_out = {} \n",
    "bigram = re.escape(' '.join(best)) \n",
    "# p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)') \n",
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'(?<!\\S)s\\ </w>(?!\\S)', re.UNICODE)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'T o k e n i z a t i o n </w>': 2,\n",
       "             'i s </w>': 2,\n",
       "             't h e </w>': 3,\n",
       "             'p r o c e s s </w>': 1,\n",
       "             'o f </w>': 2,\n",
       "             'b r e a k i n g </w>': 1,\n",
       "             'd o w n </w>': 1,\n",
       "             'a </w>': 1,\n",
       "             's e q u e n c e </w>': 1,\n",
       "             't e x t </w>': 2,\n",
       "             'i n t o </w>': 2,\n",
       "             's m a l l e r </w>': 1,\n",
       "             'u n i t s </w>': 1,\n",
       "             'c a l l e d </w>': 1,\n",
       "             't o k e n s , </w>': 1,\n",
       "             'w h i c h </w>': 1,\n",
       "             'c a n </w>': 1,\n",
       "             'b e </w>': 1,\n",
       "             'w o r d s , </w>': 1,\n",
       "             'p h r a s e s , </w>': 1,\n",
       "             'o r </w>': 1,\n",
       "             'e v e n </w>': 1,\n",
       "             'i n d i v i d u a l </w>': 1,\n",
       "             'c h a r a c t e r s </w>': 1,\n",
       "             'o f t e n </w>': 1,\n",
       "             'f i r s t </w>': 1,\n",
       "             's t e p </w>': 1,\n",
       "             'i n </w>': 1,\n",
       "             'n a t u r a l </w>': 1,\n",
       "             'l a n g u a g e s </w>': 1,\n",
       "             'p r o c e s s i n g </w>': 2,\n",
       "             't a s k s </w>': 1,\n",
       "             's u c h </w>': 2,\n",
       "             'a s </w>': 3,\n",
       "             'c l a s s i f i c a t i o n , </w>': 1,\n",
       "             'n a m e d </w>': 1,\n",
       "             'e n t i t y </w>': 1,\n",
       "             'r e c o g n i t i o n , </w>': 1,\n",
       "             'a n d </w>': 1,\n",
       "             's e n t i m e n t </w>': 1,\n",
       "             'a n a l y s i s </w>': 1,\n",
       "             'T h e </w>': 1,\n",
       "             'r e s u l t i n g </w>': 1,\n",
       "             't o k e n s </w>': 2,\n",
       "             'a r e </w>': 2,\n",
       "             't y p i c a l l y </w>': 1,\n",
       "             'u s e d </w>': 1,\n",
       "             'i n p u t </w>': 1,\n",
       "             't o </w>': 2,\n",
       "             'f u r t h e r </w>': 1,\n",
       "             's t e p s , </w>': 1,\n",
       "             'v e c t o r i z a t i o n , </w>': 1,\n",
       "             'w h e r e </w>': 1,\n",
       "             'c o n v e r t e d </w>': 1,\n",
       "             'n u m e r i c a l </w>': 1,\n",
       "             'r e p r e s e n t a t i o n s </w>': 1,\n",
       "             'f o r </w>': 1,\n",
       "             'm a c h i n e </w>': 1,\n",
       "             'l e a r n i n g </w>': 1,\n",
       "             'm o d e l s </w>': 1,\n",
       "             'u s e </w>': 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in vocab: \n",
    "        w_out = p.sub(''.join(best), word) \n",
    "        v_out[w_out] = vocab[word]\n",
    "\n",
    "vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
